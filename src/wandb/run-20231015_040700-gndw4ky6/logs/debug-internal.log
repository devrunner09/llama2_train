2023-10-15 04:07:00,188 INFO    StreamThr :2869 [internal.py:wandb_internal():86] W&B internal server running at pid: 2869, started at: 2023-10-15 04:07:00.187773
2023-10-15 04:07:00,189 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status
2023-10-15 04:07:00,191 INFO    WriterThread:2869 [datastore.py:open_for_write():85] open: /workdir/llama-recipes/src/wandb/run-20231015_040700-gndw4ky6/run-gndw4ky6.wandb
2023-10-15 04:07:00,193 DEBUG   SenderThread:2869 [sender.py:send():379] send: header
2023-10-15 04:07:00,193 DEBUG   SenderThread:2869 [sender.py:send():379] send: run
2023-10-15 04:07:00,851 INFO    SenderThread:2869 [dir_watcher.py:__init__():211] watching files in: /workdir/llama-recipes/src/wandb/run-20231015_040700-gndw4ky6/files
2023-10-15 04:07:00,851 INFO    SenderThread:2869 [sender.py:_start_run_threads():1121] run started: gndw4ky6 with start time 1697342820.188679
2023-10-15 04:07:00,852 DEBUG   SenderThread:2869 [sender.py:send_request():406] send_request: summary_record
2023-10-15 04:07:00,852 INFO    SenderThread:2869 [sender.py:_save_file():1375] saving file wandb-summary.json with policy end
2023-10-15 04:07:00,859 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: check_version
2023-10-15 04:07:00,859 DEBUG   SenderThread:2869 [sender.py:send_request():406] send_request: check_version
2023-10-15 04:07:01,142 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: run_start
2023-10-15 04:07:01,150 DEBUG   HandlerThread:2869 [system_info.py:__init__():31] System info init
2023-10-15 04:07:01,150 DEBUG   HandlerThread:2869 [system_info.py:__init__():46] System info init done
2023-10-15 04:07:01,150 INFO    HandlerThread:2869 [system_monitor.py:start():181] Starting system monitor
2023-10-15 04:07:01,150 INFO    SystemMonitor:2869 [system_monitor.py:_start():145] Starting system asset monitoring threads
2023-10-15 04:07:01,151 INFO    HandlerThread:2869 [system_monitor.py:probe():201] Collecting system info
2023-10-15 04:07:01,151 INFO    SystemMonitor:2869 [interfaces.py:start():190] Started cpu monitoring
2023-10-15 04:07:01,152 INFO    SystemMonitor:2869 [interfaces.py:start():190] Started disk monitoring
2023-10-15 04:07:01,153 INFO    SystemMonitor:2869 [interfaces.py:start():190] Started gpu monitoring
2023-10-15 04:07:01,154 INFO    SystemMonitor:2869 [interfaces.py:start():190] Started memory monitoring
2023-10-15 04:07:01,155 INFO    SystemMonitor:2869 [interfaces.py:start():190] Started network monitoring
2023-10-15 04:07:01,164 DEBUG   HandlerThread:2869 [system_info.py:probe():195] Probing system
2023-10-15 04:07:01,164 DEBUG   HandlerThread:2869 [system_info.py:probe():240] Probing system done
2023-10-15 04:07:01,164 DEBUG   HandlerThread:2869 [system_monitor.py:probe():210] {'os': 'Linux-5.4.0-162-generic-x86_64-with-glibc2.35', 'python': '3.10.12', 'heartbeatAt': '2023-10-15T04:07:01.164523', 'startedAt': '2023-10-15T04:07:00.180691', 'docker': None, 'cuda': None, 'args': ('--use_peft', '--peft_method', 'lora', '--model_name', '/workdir/ViLLM/finetuned_models', '--output_dir', '/workdir/ViLLM/26k_finetuned'), 'state': 'running', 'program': '-m llama_recipes.finetuning', 'host': '017aeb6f8f0a', 'username': 'root', 'executable': '/workdir/env/bin/python', 'cpu_count': 8, 'cpu_count_logical': 8, 'cpu_freq': {'current': 2194.8430000000003, 'min': 0.0, 'max': 0.0}, 'cpu_freq_per_core': [{'current': 2194.843, 'min': 0.0, 'max': 0.0}, {'current': 2194.843, 'min': 0.0, 'max': 0.0}, {'current': 2194.843, 'min': 0.0, 'max': 0.0}, {'current': 2194.843, 'min': 0.0, 'max': 0.0}, {'current': 2194.843, 'min': 0.0, 'max': 0.0}, {'current': 2194.843, 'min': 0.0, 'max': 0.0}, {'current': 2194.843, 'min': 0.0, 'max': 0.0}, {'current': 2194.843, 'min': 0.0, 'max': 0.0}], 'disk': {'total': 497.48069763183594, 'used': 418.21631240844727}, 'gpu': 'NVIDIA A30', 'gpu_count': 1, 'gpu_devices': [{'name': 'NVIDIA A30', 'memory_total': 25769803776}], 'memory': {'total': 31.319129943847656}}
2023-10-15 04:07:01,164 INFO    HandlerThread:2869 [system_monitor.py:probe():211] Finished collecting system info
2023-10-15 04:07:01,164 INFO    HandlerThread:2869 [system_monitor.py:probe():214] Publishing system info
2023-10-15 04:07:01,164 DEBUG   HandlerThread:2869 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
2023-10-15 04:07:01,164 DEBUG   HandlerThread:2869 [system_info.py:_save_pip():67] Saving pip packages done
2023-10-15 04:07:01,165 INFO    HandlerThread:2869 [system_monitor.py:probe():216] Finished publishing system info
2023-10-15 04:07:01,168 DEBUG   SenderThread:2869 [sender.py:send():379] send: files
2023-10-15 04:07:01,168 INFO    SenderThread:2869 [sender.py:_save_file():1375] saving file wandb-metadata.json with policy now
2023-10-15 04:07:01,173 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: stop_status
2023-10-15 04:07:01,174 DEBUG   SenderThread:2869 [sender.py:send_request():406] send_request: stop_status
2023-10-15 04:07:01,609 DEBUG   SenderThread:2869 [sender.py:send():379] send: telemetry
2023-10-15 04:07:01,853 INFO    Thread-12 :2869 [dir_watcher.py:_on_file_created():271] file/dir created: /workdir/llama-recipes/src/wandb/run-20231015_040700-gndw4ky6/files/wandb-metadata.json
2023-10-15 04:07:01,853 INFO    Thread-12 :2869 [dir_watcher.py:_on_file_created():271] file/dir created: /workdir/llama-recipes/src/wandb/run-20231015_040700-gndw4ky6/files/requirements.txt
2023-10-15 04:07:01,853 INFO    Thread-12 :2869 [dir_watcher.py:_on_file_created():271] file/dir created: /workdir/llama-recipes/src/wandb/run-20231015_040700-gndw4ky6/files/wandb-summary.json
2023-10-15 04:07:02,050 INFO    wandb-upload_0:2869 [upload_job.py:push():131] Uploaded file /tmp/tmp5brhkgtbwandb/qco74zuy-wandb-metadata.json
2023-10-15 04:07:05,611 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status_report
2023-10-15 04:07:10,611 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status_report
2023-10-15 04:07:15,612 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status_report
2023-10-15 04:07:16,173 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: stop_status
2023-10-15 04:07:16,173 DEBUG   SenderThread:2869 [sender.py:send_request():406] send_request: stop_status
2023-10-15 04:07:21,379 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status_report
2023-10-15 04:07:26,379 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status_report
2023-10-15 04:07:31,173 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: stop_status
2023-10-15 04:07:31,173 DEBUG   SenderThread:2869 [sender.py:send_request():406] send_request: stop_status
2023-10-15 04:07:31,415 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status_report
2023-10-15 04:07:31,863 INFO    Thread-12 :2869 [dir_watcher.py:_on_file_modified():288] file/dir modified: /workdir/llama-recipes/src/wandb/run-20231015_040700-gndw4ky6/files/config.yaml
2023-10-15 04:07:35,168 INFO    memory    :2869 [interfaces.py:monitor():140] Process proc.memory.rssMB has exited.
2023-10-15 04:07:35,169 DEBUG   SystemMonitor:2869 [system_monitor.py:_start():159] Starting system metrics aggregation loop
2023-10-15 04:07:35,170 DEBUG   SystemMonitor:2869 [system_monitor.py:_start():166] Finished system metrics aggregation loop
2023-10-15 04:07:35,170 DEBUG   SystemMonitor:2869 [system_monitor.py:_start():170] Publishing last batch of metrics
2023-10-15 04:07:35,175 DEBUG   SenderThread:2869 [sender.py:send():379] send: stats
2023-10-15 04:07:37,176 DEBUG   HandlerThread:2869 [handler.py:handle_request():144] handle_request: status_report
2023-10-15 04:07:37,178 INFO    MainThread:2869 [internal.py:handle_exit():76] Internal process exited
